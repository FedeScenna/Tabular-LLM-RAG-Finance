{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint, HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"data/database.db\")\n",
    "tickers = pd.read_sql_query(\"SELECT distinct Security FROM master_ticker\", conn)[\"Security\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"keys.yaml\") as keys:\n",
    "    try:\n",
    "        api_keys = yaml.safe_load(keys)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\feder\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\feder\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\feder\\anaconda3\\envs\\nlp\\Lib\\site-packages\\langchain_huggingface\\chat_models\\huggingface.py:130: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_community.llms.huggingface_text_gen_inference import (  # type: ignore[import-not-found]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = api_keys[\"hf_model\"]\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    temperature=0,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(\"data/wikipedia/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\feder\\anaconda3\\envs\\nlp\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:27<00:00,  3.43s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "model_name = 'HuggingFaceH4/zephyr-7b-beta'\n",
    "bnb_config = BitsAndBytesConfig(\n",
    " load_in_4bit=True,\n",
    " bnb_4bit_use_double_quant=True,\n",
    " bnb_4bit_quant_type=\"nf4\",\n",
    " bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\feder\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[0;32m      6\u001b[0m text_generation_pipeline \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m----> 7\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m,\n\u001b[0;32m      8\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m      9\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m     11\u001b[0m     repetition_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.1\u001b[39m,\n\u001b[0;32m     12\u001b[0m     return_full_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m llm \u001b[38;5;241m=\u001b[39m HuggingFacePipeline(pipeline\u001b[38;5;241m=\u001b[39mtext_generation_pipeline)\n\u001b[0;32m     17\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m<|system|>\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124mAnswer the question based on your knowledge. Use the following context to help:\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m<|assistant|>\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import pipeline\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=400,\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<|system|>\n",
    "Answer the question based on your knowledge. Use the following context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "\n",
    "<|user|>\n",
    "{question}\n",
    "\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Step 4: Query the vectorstore for relevant context\n",
    "def get_relevant_context(question, top_k=3):\n",
    "    \"\"\"\n",
    "    Perform similarity search to retrieve the most relevant chunks from the vectorstore.\n",
    "    \"\"\"\n",
    "    results = vectorstore.similarity_search(question, k=top_k)\n",
    "    context = \"\\n\\n\".join([result.page_content for result in results])\n",
    "    return context\n",
    "\n",
    "# Step 5: Integrate everything for answering questions\n",
    "def ask_question(question):\n",
    "    \"\"\"\n",
    "    Retrieve relevant context from the vectorstore and use the LLMChain to answer the question.\n",
    "    \"\"\"\n",
    "    context = get_relevant_context(question)\n",
    "    result = llm_chain.run({\"context\": context, \"question\": question})\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "question = \"What is AES?\"\n",
    "answer = ask_question(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_schema(connection):\n",
    "    \"\"\"\n",
    "    Extract the database schema as a string.\n",
    "    \"\"\"\n",
    "    schema = []\n",
    "    cursor = connection.cursor()\n",
    "    for table in cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall():\n",
    "        table_name = table[0]\n",
    "        schema.append(f\"Table: {table_name}\")\n",
    "        columns = cursor.execute(f\"PRAGMA table_info({table_name});\").fetchall()\n",
    "        for col in columns:\n",
    "            schema.append(f\"    Column: {col[1]} ({col[2]})\")\n",
    "    return \"\\n\".join(schema)\n",
    "\n",
    "schema = get_db_schema(conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_schema_prompt = \"\"\"\n",
    "<|system|>\n",
    "You are an assistant that translates user questions into SQL queries for an SQLite database. \n",
    "The database schema is as follows:\n",
    "Price database: contains all prices from SP500 companies.\n",
    "Income statements: contains financial information from SP500 companies.\n",
    "\n",
    "{schema}\n",
    "\n",
    "<|user|>\n",
    "{question}\n",
    "\n",
    "<|assistant|>\n",
    "Here is the corresponding SQL query:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sql(question):\n",
    "    \"\"\"\n",
    "    Generate and execute a SQL query for the given question.\n",
    "    \"\"\"\n",
    "    # Prepare the inputs for the LLMChain\n",
    "    inputs = {\n",
    "        \"context\": schema,  # Provide the database schema as context\n",
    "        \"question\": question\n",
    "    }\n",
    "    \n",
    "    # Generate the SQL query\n",
    "    sql_query = llm_chain.run(inputs)\n",
    "    \n",
    "    # Execute the SQL query on the database\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql_query)\n",
    "        result = cursor.fetchall()\n",
    "        return {\"query\": sql_query, \"result\": result}\n",
    "    except sqlite3.Error as e:\n",
    "        return {\"query\": sql_query, \"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\feder\\anaconda3\\envs\\nlp\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query:\n",
      "\n",
      "<|system|>\n",
      "Answer the question based on your knowledge. Use the following context to help:\n",
      "\n",
      "Table: income_statements\n",
      "    Column: date (TEXT)\n",
      "    Column: symbol (TEXT)\n",
      "    Column: reportedCurrency (TEXT)\n",
      "    Column: cik (TEXT)\n",
      "    Column: fillingDate (TEXT)\n",
      "    Column: acceptedDate (TEXT)\n",
      "    Column: calendarYear (TEXT)\n",
      "    Column: period (TEXT)\n",
      "    Column: revenue (INTEGER)\n",
      "    Column: costOfRevenue (INTEGER)\n",
      "    Column: grossProfit (INTEGER)\n",
      "    Column: grossProfitRatio (REAL)\n",
      "    Column: researchAndDevelopmentExpenses (INTEGER)\n",
      "    Column: generalAndAdministrativeExpenses (INTEGER)\n",
      "    Column: sellingAndMarketingExpenses (INTEGER)\n",
      "    Column: sellingGeneralAndAdministrativeExpenses (INTEGER)\n",
      "    Column: otherExpenses (INTEGER)\n",
      "    Column: operatingExpenses (INTEGER)\n",
      "    Column: costAndExpenses (INTEGER)\n",
      "    Column: interestIncome (INTEGER)\n",
      "    Column: interestExpense (INTEGER)\n",
      "    Column: depreciationAndAmortization (INTEGER)\n",
      "    Column: ebitda (INTEGER)\n",
      "    Column: ebitdaratio (REAL)\n",
      "    Column: operatingIncome (INTEGER)\n",
      "    Column: operatingIncomeRatio (REAL)\n",
      "    Column: totalOtherIncomeExpensesNet (INTEGER)\n",
      "    Column: incomeBeforeTax (INTEGER)\n",
      "    Column: incomeBeforeTaxRatio (REAL)\n",
      "    Column: incomeTaxExpense (INTEGER)\n",
      "    Column: netIncome (INTEGER)\n",
      "    Column: netIncomeRatio (REAL)\n",
      "    Column: eps (REAL)\n",
      "    Column: epsdiluted (REAL)\n",
      "    Column: weightedAverageShsOut (INTEGER)\n",
      "    Column: weightedAverageShsOutDil (INTEGER)\n",
      "    Column: link (TEXT)\n",
      "    Column: finalLink (TEXT)\n",
      "Table: price_data\n",
      "    Column: date (TIMESTAMP)\n",
      "    Column: ticker (TEXT)\n",
      "    Column: close (REAL)\n",
      "    Column: high (REAL)\n",
      "    Column: low (REAL)\n",
      "    Column: open (REAL)\n",
      "    Column: volume (REAL)\n",
      "    Column: garman_klass_vol (REAL)\n",
      "    Column: rsi (REAL)\n",
      "    Column: bb_low (REAL)\n",
      "    Column: bb_mid (REAL)\n",
      "    Column: bb_high (REAL)\n",
      "    Column: sharpe_ratio (REAL)\n",
      "    Column: atr (REAL)\n",
      "    Column: macd (REAL)\n",
      "    Column: dollar_volume (REAL)\n",
      "    Column: return_1d (REAL)\n",
      "    Column: return_2d (REAL)\n",
      "    Column: return_3d (REAL)\n",
      "    Column: return_6d (REAL)\n",
      "    Column: return_9d (REAL)\n",
      "    Column: return_12d (REAL)\n",
      "    Column: Mkt-RF (REAL)\n",
      "    Column: SMB (REAL)\n",
      "    Column: HML (REAL)\n",
      "    Column: RMW (REAL)\n",
      "    Column: CMA (REAL)\n",
      "Table: master_ticker\n",
      "    Column: index (INTEGER)\n",
      "    Column: ticker (TEXT)\n",
      "    Column: Security (TEXT)\n",
      "    Column: GICS Sector (TEXT)\n",
      "    Column: GICS Sub-Industry (TEXT)\n",
      "    Column: Headquarters Location (TEXT)\n",
      "    Column: Date added (TEXT)\n",
      "    Column: CIK (INTEGER)\n",
      "    Column: Founded (TEXT)\n",
      "\n",
      "\n",
      "<|user|>\n",
      "List all securities with a market value greater than $1,000,000.\n",
      "\n",
      "<|assistant|>\n",
      "To list all securities with a market value greater than $1,000,000 using this database schema, you would need to join the income_statements and price_data tables to calculate the market value for each security, and then filter the results based on the market value threshold. Here's an example SQL query:\n",
      "\n",
      "```sql\n",
      "SELECT DISTINCT m.Security, p.close * p.volume AS marketValue\n",
      "FROM (\n",
      "    SELECT DISTINCT ticker\n",
      "    FROM income_statements\n",
      "    WHERE YEAR(date) = YEAR(CURDATE()) AND MONTH(date) = MONTH(CURDATE())\n",
      ") AS i\n",
      "JOIN (\n",
      "    SELECT DISTINCT ticker\n",
      "    FROM price_data\n",
      "    WHERE date = (\n",
      "        SELECT MAX(date)\n",
      "        FROM price_data\n",
      "        WHERE ticker = price_data.ticker\n",
      "    )\n",
      ") AS p ON i.ticker = p.ticker\n",
      "JOIN master_ticker AS m ON i.ticker = m.ticker\n",
      "WHERE marketValue > 1000000\n",
      "ORDER BY marketValue DESC;\n",
      "```\n",
      "\n",
      "This query first selects all unique tickers from the income_statements table that have reports in the current year and month. It then joins this list of tickers with the price_data table to get the most recent closing price and volume for each security. The market value is calculated by multiplying the closing price and volume together. Finally, it joins this list of tickers with the master_ticker table to get the full name of each security. The results are filtered to only include securities with a market value greater than $1,000,000, and sorted by descending market value.\n",
      "Error executing query: near \"<\": syntax error\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "question = \"List all securities with a market value greater than $1,000,000.\"\n",
    "output = text_to_sql(question)\n",
    "\n",
    "print(\"Generated SQL Query:\")\n",
    "print(output[\"query\"])\n",
    "\n",
    "if \"error\" in output:\n",
    "    print(\"Error executing query:\", output[\"error\"])\n",
    "else:\n",
    "    print(\"Query Result:\")\n",
    "    for row in output[\"result\"]:\n",
    "        print(row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
