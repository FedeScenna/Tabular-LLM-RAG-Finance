{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "conn = sqlite3.connect(\"data/database.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM price_data\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>garman_klass_vol</th>\n",
       "      <th>rsi</th>\n",
       "      <th>bb_low</th>\n",
       "      <th>...</th>\n",
       "      <th>return_2d</th>\n",
       "      <th>return_3d</th>\n",
       "      <th>return_6d</th>\n",
       "      <th>return_9d</th>\n",
       "      <th>return_12d</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-07 00:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>42.503578</td>\n",
       "      <td>42.539341</td>\n",
       "      <td>41.580830</td>\n",
       "      <td>41.816879</td>\n",
       "      <td>2749586.0</td>\n",
       "      <td>-0.001839</td>\n",
       "      <td>56.320226</td>\n",
       "      <td>3.634578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017178</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>-0.002089</td>\n",
       "      <td>-0.018428</td>\n",
       "      <td>-0.034321</td>\n",
       "      <td>0.027925</td>\n",
       "      <td>0.014862</td>\n",
       "      <td>0.026530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-07 00:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>18.559999</td>\n",
       "      <td>18.676071</td>\n",
       "      <td>18.477858</td>\n",
       "      <td>18.620714</td>\n",
       "      <td>370280400.0</td>\n",
       "      <td>-0.006857</td>\n",
       "      <td>44.058787</td>\n",
       "      <td>2.785700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>-0.005722</td>\n",
       "      <td>-0.004447</td>\n",
       "      <td>0.053902</td>\n",
       "      <td>0.008192</td>\n",
       "      <td>-0.033890</td>\n",
       "      <td>0.145374</td>\n",
       "      <td>0.193726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-07 00:00:00</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>48.889999</td>\n",
       "      <td>49.029999</td>\n",
       "      <td>47.660000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>6979500.0</td>\n",
       "      <td>-0.067514</td>\n",
       "      <td>46.153243</td>\n",
       "      <td>3.435299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012079</td>\n",
       "      <td>0.006492</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>0.058951</td>\n",
       "      <td>0.079235</td>\n",
       "      <td>-0.097550</td>\n",
       "      <td>0.208368</td>\n",
       "      <td>-0.057851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-07 00:00:00</td>\n",
       "      <td>ABT</td>\n",
       "      <td>37.180000</td>\n",
       "      <td>37.209999</td>\n",
       "      <td>36.650002</td>\n",
       "      <td>36.770000</td>\n",
       "      <td>12028000.0</td>\n",
       "      <td>-0.014735</td>\n",
       "      <td>46.146218</td>\n",
       "      <td>3.379105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>-0.001969</td>\n",
       "      <td>-0.026242</td>\n",
       "      <td>0.059898</td>\n",
       "      <td>-0.027832</td>\n",
       "      <td>0.136349</td>\n",
       "      <td>-0.043127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-02-07 00:00:00</td>\n",
       "      <td>ACGL</td>\n",
       "      <td>17.583332</td>\n",
       "      <td>17.663334</td>\n",
       "      <td>17.410000</td>\n",
       "      <td>17.603333</td>\n",
       "      <td>1496100.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>30.310212</td>\n",
       "      <td>2.913167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>-0.001826</td>\n",
       "      <td>-0.004815</td>\n",
       "      <td>-0.001795</td>\n",
       "      <td>-0.003656</td>\n",
       "      <td>-0.064590</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>0.148707</td>\n",
       "      <td>-0.067339</td>\n",
       "      <td>-0.136078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date ticker      close       high        low       open  \\\n",
       "0  2014-02-07 00:00:00      A  42.503578  42.539341  41.580830  41.816879   \n",
       "1  2014-02-07 00:00:00   AAPL  18.559999  18.676071  18.477858  18.620714   \n",
       "2  2014-02-07 00:00:00   ABBV  48.889999  49.029999  47.660000  48.000000   \n",
       "3  2014-02-07 00:00:00    ABT  37.180000  37.209999  36.650002  36.770000   \n",
       "4  2014-02-07 00:00:00   ACGL  17.583332  17.663334  17.410000  17.603333   \n",
       "\n",
       "        volume  garman_klass_vol        rsi    bb_low  ...  return_2d  \\\n",
       "0    2749586.0         -0.001839  56.320226  3.634578  ...   0.017178   \n",
       "1  370280400.0         -0.006857  44.058787  2.785700  ...   0.009901   \n",
       "2    6979500.0         -0.067514  46.153243  3.435299  ...   0.012079   \n",
       "3   12028000.0         -0.014735  46.146218  3.379105  ...   0.011352   \n",
       "4    1496100.0          0.000104  30.310212  2.913167  ...  -0.000757   \n",
       "\n",
       "   return_3d  return_6d  return_9d  return_12d    Mkt-RF       SMB       HML  \\\n",
       "0   0.009198  -0.000252   0.002117   -0.002089 -0.018428 -0.034321  0.027925   \n",
       "1   0.009090   0.007530  -0.005722   -0.004447  0.053902  0.008192 -0.033890   \n",
       "2   0.006492   0.001991   0.004795   -0.000323  0.058951  0.079235 -0.097550   \n",
       "3   0.008480   0.002944   0.002665   -0.001969 -0.026242  0.059898 -0.027832   \n",
       "4  -0.001826  -0.004815  -0.001795   -0.003656 -0.064590 -0.034905  0.148707   \n",
       "\n",
       "        RMW       CMA  \n",
       "0  0.014862  0.026530  \n",
       "1  0.145374  0.193726  \n",
       "2  0.208368 -0.057851  \n",
       "3  0.136349 -0.043127  \n",
       "4 -0.067339 -0.136078  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded in comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 265\u001b[0m\n\u001b[0;32m    262\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 265\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 241\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    235\u001b[0m model_runner\u001b[38;5;241m.\u001b[39mpreprocess_data(\n\u001b[0;32m    236\u001b[0m     features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrsi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msharpe_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_1d\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    237\u001b[0m     target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_2d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    238\u001b[0m )\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# Create hierarchical model\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m bayesian_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_hierarchical_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# Run inference\u001b[39;00m\n\u001b[0;32m    244\u001b[0m trace \u001b[38;5;241m=\u001b[39m model_runner\u001b[38;5;241m.\u001b[39mrun_inference(bayesian_model)\n",
      "Cell \u001b[1;32mIn[29], line 93\u001b[0m, in \u001b[0;36mFinancialBayesianModel.create_hierarchical_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m     sigma \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mHalfNormal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m'\u001b[39m, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# Likelihood with ticker-specific intercepts and slopes\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     mu \u001b[38;5;241m=\u001b[39m \u001b[43malpha\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtickers_train\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m pm\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, betas[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtickers_train]\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     94\u001b[0m     likelihood \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mNormal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m, mu\u001b[38;5;241m=\u001b[39mmu, sigma\u001b[38;5;241m=\u001b[39msigma, observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\pymc\\Lib\\site-packages\\pytensor\\tensor\\variable.py:486\u001b[0m, in \u001b[0;36m_tensor_py_operators.__getitem__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    478\u001b[0m     index_dim_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;66;03m# Python arrays can contain a mixture of bools and integers,\u001b[39;00m\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# which requires complex rules to handle all special cases.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;66;03m# indexing, it is safe to throw an error if we encounter\u001b[39;00m\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;66;03m# any of these difficult cases.\u001b[39;00m\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mincludes_bool\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    487\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    488\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorType does not support Python bools \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor indexing, such as tensor[[True, False]]. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor[numpy.array([True, False])].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    493\u001b[0m         )\n\u001b[0;32m    494\u001b[0m     index_dim_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\pymc\\Lib\\site-packages\\pytensor\\tensor\\variable.py:454\u001b[0m, in \u001b[0;36m_tensor_py_operators.__getitem__.<locals>.includes_bool\u001b[1;34m(args_el)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_el, Variable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_el, Iterable):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args_el:\n\u001b[1;32m--> 454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mincludes_bool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mel\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    455\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\pymc\\Lib\\site-packages\\pytensor\\tensor\\variable.py:454\u001b[0m, in \u001b[0;36m_tensor_py_operators.__getitem__.<locals>.includes_bool\u001b[1;34m(args_el)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_el, Variable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_el, Iterable):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args_el:\n\u001b[1;32m--> 454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mincludes_bool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mel\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    455\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: _tensor_py_operators.__getitem__.<locals>.includes_bool at line 454 (9963 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\pymc\\Lib\\site-packages\\pytensor\\tensor\\variable.py:454\u001b[0m, in \u001b[0;36m_tensor_py_operators.__getitem__.<locals>.includes_bool\u001b[1;34m(args_el)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_el, Variable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_el, Iterable):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args_el:\n\u001b[1;32m--> 454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mincludes_bool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mel\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    455\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\pymc\\Lib\\site-packages\\pytensor\\tensor\\variable.py:452\u001b[0m, in \u001b[0;36m_tensor_py_operators.__getitem__.<locals>.includes_bool\u001b[1;34m(args_el)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_el, (np\u001b[38;5;241m.\u001b[39mbool_, \u001b[38;5;28mbool\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(args_el, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m args_el\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m ):\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_el, Variable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_el, Iterable):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args_el:\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m includes_bool(el):\n",
      "File \u001b[1;32m<frozen abc>:119\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded in comparison"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class FinancialBayesianModel:\n",
    "    def __init__(self, data, max_tickers=50):\n",
    "        \"\"\"\n",
    "        Initialize the Bayesian financial model with ticker limit\n",
    "        \n",
    "        Parameters:\n",
    "        data (pd.DataFrame): Financial time series data\n",
    "        max_tickers (int): Maximum number of unique tickers to process\n",
    "        \"\"\"\n",
    "        # Limit the number of unique tickers\n",
    "        unique_tickers = data['ticker'].unique()\n",
    "        if len(unique_tickers) > max_tickers:\n",
    "            selected_tickers = np.random.choice(unique_tickers, max_tickers, replace=False)\n",
    "            self.original_data = data[data['ticker'].isin(selected_tickers)].copy()\n",
    "        else:\n",
    "            self.original_data = data.copy()\n",
    "        \n",
    "        self.data = None\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def preprocess_data(self, \n",
    "                         features=['close', 'volume', 'rsi', 'sharpe_ratio'],\n",
    "                         target='return_2d', \n",
    "                         test_size=0.2):\n",
    "        \"\"\"\n",
    "        Preprocess data with memory-efficient approach\n",
    "        \"\"\"\n",
    "        # Sort and prepare data\n",
    "        df = self.original_data.sort_values(['date', 'ticker'])\n",
    "        \n",
    "        # Select and prepare columns\n",
    "        cols_to_use = features + [target, 'ticker']\n",
    "        df_subset = df[cols_to_use].dropna()\n",
    "        \n",
    "        # Use categorical encoding for tickers\n",
    "        df_subset['ticker_code'] = pd.Categorical(df_subset['ticker']).codes\n",
    "        \n",
    "        # Prepare features and target\n",
    "        X = df_subset[features].values\n",
    "        y = df_subset[target].values\n",
    "        tickers = df_subset['ticker_code'].values\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Split data with stratification\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test, \\\n",
    "        self.tickers_train, self.tickers_test = \\\n",
    "            train_test_split(X_scaled, y, tickers, \n",
    "                             test_size=test_size, \n",
    "                             stratify=tickers, \n",
    "                             random_state=42)\n",
    "        \n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.unique_tickers = np.unique(tickers)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_hierarchical_model(self):\n",
    "        \"\"\"\n",
    "        Simplified hierarchical model to avoid recursion\n",
    "        \"\"\"\n",
    "        with pm.Model() as model:\n",
    "            # Global parameters with less complexity\n",
    "            mu_alpha = pm.Normal('mu_alpha', mu=0, sigma=1)\n",
    "            sigma_alpha = pm.HalfNormal('sigma_alpha', sigma=0.5)\n",
    "            \n",
    "            # Global coefficients\n",
    "            mu_betas = pm.Normal('mu_betas', mu=0, sigma=0.5, \n",
    "                                 shape=self.X_train.shape[1])\n",
    "            sigma_betas = pm.HalfNormal('sigma_betas', sigma=0.5, \n",
    "                                        shape=self.X_train.shape[1])\n",
    "            \n",
    "            # Model variance\n",
    "            sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "            \n",
    "            # Linear model with vectorized computation\n",
    "            mu = pm.math.dot(self.X_train, mu_betas)\n",
    "            \n",
    "            # Likelihood\n",
    "            likelihood = pm.Normal('returns', \n",
    "                                   mu=mu, \n",
    "                                   sigma=sigma, \n",
    "                                   observed=self.y_train)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def run_inference(self, model, draws=1000, tune=500):\n",
    "        \"\"\"\n",
    "        Run inference with reduced complexity\n",
    "        \"\"\"\n",
    "        with model:\n",
    "            # Use NUTS sampler with adjusted parameters\n",
    "            trace = pm.sample(draws=draws, \n",
    "                              tune=tune, \n",
    "                              return_inferrable=True,\n",
    "                              cores=1,  # Avoid multiprocessing issues\n",
    "                              target_accept=0.9)\n",
    "        \n",
    "        return trace\n",
    "    \n",
    "    def predict(self, trace):\n",
    "        \"\"\"\n",
    "        Make predictions with simplified approach\n",
    "        \"\"\"\n",
    "        # Extract posterior samples\n",
    "        mu_betas = trace.posterior['mu_betas']\n",
    "        sigma = trace.posterior['sigma']\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred_samples = np.dot(self.X_test, mu_betas.T)\n",
    "        \n",
    "        return {\n",
    "            'true_returns': self.y_test,\n",
    "            'mean_prediction': y_pred_samples.mean(axis=0),\n",
    "            'lower_ci': np.percentile(y_pred_samples, 2.5, axis=0),\n",
    "            'upper_ci': np.percentile(y_pred_samples, 97.5, axis=0)\n",
    "        }\n",
    "    \n",
    "    def evaluate_predictions(self, predictions):\n",
    "        \"\"\"\n",
    "        Evaluate model predictions\n",
    "        \"\"\"\n",
    "        mse = np.mean((predictions['true_returns'] - predictions['mean_prediction'])**2)\n",
    "        mae = np.mean(np.abs(predictions['true_returns'] - predictions['mean_prediction']))\n",
    "        \n",
    "        return {\n",
    "            'MSE': mse,\n",
    "            'MAE': mae,\n",
    "            'Coverage': np.mean((predictions['true_returns'] >= predictions['lower_ci']) & \n",
    "                                (predictions['true_returns'] <= predictions['upper_ci']))\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    # Load your financial data\n",
    "    df = pd.read_csv('your_financial_data.csv')\n",
    "    \n",
    "    # Initialize model with ticker limit\n",
    "    model_runner = FinancialBayesianModel(df, max_tickers=50)\n",
    "    \n",
    "    # Preprocess data\n",
    "    model_runner.preprocess_data(\n",
    "        features=['close', 'volume', 'rsi', 'sharpe_ratio'],\n",
    "        target='return_2d'\n",
    "    )\n",
    "    \n",
    "    # Create and run model\n",
    "    bayesian_model = model_runner.create_hierarchical_model()\n",
    "    trace = model_runner.run_inference(bayesian_model)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model_runner.predict(trace)\n",
    "    \n",
    "    # Evaluate\n",
    "    performance = model_runner.evaluate_predictions(predictions)\n",
    "    print(\"Performance Metrics:\", performance)\n",
    "    \n",
    "    # Optional visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(predictions['true_returns'], label='Actual Returns')\n",
    "    plt.plot(predictions['mean_prediction'], label='Predicted Returns')\n",
    "    plt.fill_between(range(len(predictions['lower_ci'])), \n",
    "                     predictions['lower_ci'], \n",
    "                     predictions['upper_ci'], \n",
    "                     alpha=0.2)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'df' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m prepro \u001b[38;5;241m=\u001b[39m Preprocessor(df)\n\u001b[0;32m     25\u001b[0m prepro\u001b[38;5;241m.\u001b[39mcreate_MA()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mprepro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalerstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 21\u001b[0m, in \u001b[0;36mPreprocessor.scalerstd\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscalerstd\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 21\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler()\u001b[38;5;241m.\u001b[39mfit_transform(x\u001b[38;5;241m.\u001b[39mvalues[:,np\u001b[38;5;241m.\u001b[39mnewaxis])\u001b[38;5;241m.\u001b[39mravel())\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'df' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, data):\n",
    "        self.original_data = data.copy()\n",
    "        self.features = [ 'garman_klass_vol', 'rsi', 'bb_low', 'bb_mid', 'bb_high',\n",
    "       'sharpe_ratio', 'atr', 'macd', 'dollar_volume', 'return_1d',\n",
    "       'return_2d', 'return_3d', 'return_6d', 'return_9d', 'return_12d',\n",
    "       'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\n",
    "        self.data = None\n",
    "        self.target = None\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "\n",
    "    def create_MA(self):\n",
    "        df = self.original_data.sort_values([\"date\",\"ticker\"])\n",
    "        df['MA_10'] = df.groupby('ticker')['close'].transform(lambda x: x.rolling(window=10).mean())\n",
    "        df['MA_50'] = df.groupby('ticker')['close'].transform(lambda x: x.rolling(window=50).mean())\n",
    "\n",
    "        self.data = df\n",
    "    \n",
    "    def scale_group(group): \n",
    "        scaler = StandardScaler()\n",
    "        numerical_cols = self.features + [\"MA_10\",\"MA_50\"]\n",
    "        group[numerical_cols] = scaler.fit_transform(group[numerical_cols])\n",
    "    return df.groupby(\"ticker\").apply(scale_group).reset_index(drop=True)\n",
    "\n",
    "prepro = Preprocessor(df)\n",
    "\n",
    "prepro.create_MA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [mu_alpha, sigma_alpha, mu_betas, sigma_betas, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1500' class='' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1500/1500 03:21&lt;00:00 Sampling chain 0, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1500' class='' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1500/1500 02:51&lt;00:00 Sampling chain 1, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 373 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (24628,4) and (4,1000,2) not aligned: 4 (dim 1) != 1000 (dim 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 177\u001b[0m\n\u001b[0;32m    174\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 177\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 159\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    156\u001b[0m trace \u001b[38;5;241m=\u001b[39m model_runner\u001b[38;5;241m.\u001b[39mrun_inference(bayesian_model)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m    162\u001b[0m performance \u001b[38;5;241m=\u001b[39m model_runner\u001b[38;5;241m.\u001b[39mevaluate_predictions(predictions)\n",
      "Cell \u001b[1;32mIn[31], line 120\u001b[0m, in \u001b[0;36mFinancialBayesianModel.predict\u001b[1;34m(self, trace)\u001b[0m\n\u001b[0;32m    117\u001b[0m sigma \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mposterior[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Predict on test data\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m y_pred_samples \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_betas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_returns\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test,\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m: y_pred_samples\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower_ci\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mpercentile(y_pred_samples, \u001b[38;5;241m2.5\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper_ci\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mpercentile(y_pred_samples, \u001b[38;5;241m97.5\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    127\u001b[0m }\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (24628,4) and (4,1000,2) not aligned: 4 (dim 1) != 1000 (dim 1)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class FinancialBayesianModel:\n",
    "    def __init__(self, data, max_tickers=50):\n",
    "        \"\"\"\n",
    "        Initialize the Bayesian financial model with ticker limit\n",
    "        \n",
    "        Parameters:\n",
    "        data (pd.DataFrame): Financial time series data\n",
    "        max_tickers (int): Maximum number of unique tickers to process\n",
    "        \"\"\"\n",
    "        # Limit the number of unique tickers\n",
    "        unique_tickers = data['ticker'].unique()\n",
    "        if len(unique_tickers) > max_tickers:\n",
    "            selected_tickers = np.random.choice(unique_tickers, max_tickers, replace=False)\n",
    "            self.original_data = data[data['ticker'].isin(selected_tickers)].copy()\n",
    "        else:\n",
    "            self.original_data = data.copy()\n",
    "        \n",
    "        self.data = None\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def preprocess_data(self, \n",
    "                         features=['close', 'volume', 'rsi', 'sharpe_ratio'],\n",
    "                         target='return_2d', \n",
    "                         test_size=0.2):\n",
    "        \"\"\"\n",
    "        Preprocess data with memory-efficient approach\n",
    "        \"\"\"\n",
    "        # Sort and prepare data\n",
    "        df = self.original_data.sort_values(['date', 'ticker'])\n",
    "        \n",
    "        # Select and prepare columns\n",
    "        cols_to_use = features + [target, 'ticker']\n",
    "        df_subset = df[cols_to_use].dropna()\n",
    "        \n",
    "        # Use categorical encoding for tickers\n",
    "        df_subset['ticker_code'] = pd.Categorical(df_subset['ticker']).codes\n",
    "        \n",
    "        # Prepare features and target\n",
    "        X = df_subset[features].values\n",
    "        y = df_subset[target].values\n",
    "        tickers = df_subset['ticker_code'].values\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Split data with stratification\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test, \\\n",
    "        self.tickers_train, self.tickers_test = \\\n",
    "            train_test_split(X_scaled, y, tickers, \n",
    "                             test_size=test_size, \n",
    "                             stratify=tickers, \n",
    "                             random_state=42)\n",
    "        \n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.unique_tickers = np.unique(tickers)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_hierarchical_model(self):\n",
    "        \"\"\"\n",
    "        Simplified hierarchical model to avoid recursion\n",
    "        \"\"\"\n",
    "        with pm.Model() as model:\n",
    "            # Global parameters with less complexity\n",
    "            mu_alpha = pm.Normal('mu_alpha', mu=0, sigma=1)\n",
    "            sigma_alpha = pm.HalfNormal('sigma_alpha', sigma=0.5)\n",
    "            \n",
    "            # Global coefficients\n",
    "            mu_betas = pm.Normal('mu_betas', mu=0, sigma=0.5, \n",
    "                                 shape=self.X_train.shape[1])\n",
    "            sigma_betas = pm.HalfNormal('sigma_betas', sigma=0.5, \n",
    "                                        shape=self.X_train.shape[1])\n",
    "            \n",
    "            # Model variance\n",
    "            sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "            \n",
    "            # Linear model with vectorized computation\n",
    "            mu = pm.math.dot(self.X_train, mu_betas)\n",
    "            \n",
    "            # Likelihood\n",
    "            likelihood = pm.Normal('returns', \n",
    "                                   mu=mu, \n",
    "                                   sigma=sigma, \n",
    "                                   observed=self.y_train)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def run_inference(self, model, draws=1000, tune=500):\n",
    "        \"\"\"\n",
    "        Run inference with reduced complexity\n",
    "        \"\"\"\n",
    "        with model:\n",
    "            # Use NUTS sampler with adjusted parameters\n",
    "            trace = pm.sample(draws=draws, \n",
    "                              tune=tune, \n",
    "                              #return_inferrable=True,\n",
    "                              cores=1,  # Avoid multiprocessing issues\n",
    "                              target_accept=0.9)\n",
    "        \n",
    "        return trace\n",
    "    \n",
    "    def predict(self, trace):\n",
    "        \"\"\"\n",
    "        Make predictions with simplified approach\n",
    "        \"\"\"\n",
    "        # Extract posterior samples\n",
    "        mu_betas = trace.posterior['mu_betas']\n",
    "        sigma = trace.posterior['sigma']\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred_samples = np.dot(self.X_test, mu_betas.T)\n",
    "        \n",
    "        return {\n",
    "            'true_returns': self.y_test,\n",
    "            'mean_prediction': y_pred_samples.mean(axis=0),\n",
    "            'lower_ci': np.percentile(y_pred_samples, 2.5, axis=0),\n",
    "            'upper_ci': np.percentile(y_pred_samples, 97.5, axis=0)\n",
    "        }\n",
    "    \n",
    "    def evaluate_predictions(self, predictions):\n",
    "        \"\"\"\n",
    "        Evaluate model predictions\n",
    "        \"\"\"\n",
    "        mse = np.mean((predictions['true_returns'] - predictions['mean_prediction'])**2)\n",
    "        mae = np.mean(np.abs(predictions['true_returns'] - predictions['mean_prediction']))\n",
    "        \n",
    "        return {\n",
    "            'MSE': mse,\n",
    "            'MAE': mae,\n",
    "            'Coverage': np.mean((predictions['true_returns'] >= predictions['lower_ci']) & \n",
    "                                (predictions['true_returns'] <= predictions['upper_ci']))\n",
    "        }\n",
    "\n",
    "def main():\n",
    "   \n",
    "    # Initialize model with ticker limit\n",
    "    model_runner = FinancialBayesianModel(df, max_tickers=50)\n",
    "    \n",
    "    # Preprocess data\n",
    "    model_runner.preprocess_data(\n",
    "        features=['close', 'volume', 'rsi', 'sharpe_ratio'],\n",
    "        target='return_2d'\n",
    "    )\n",
    "    \n",
    "    # Create and run model\n",
    "    bayesian_model = model_runner.create_hierarchical_model()\n",
    "    trace = model_runner.run_inference(bayesian_model)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model_runner.predict(trace)\n",
    "    \n",
    "    # Evaluate\n",
    "    performance = model_runner.evaluate_predictions(predictions)\n",
    "    print(\"Performance Metrics:\", performance)\n",
    "    \n",
    "    # Optional visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(predictions['true_returns'], label='Actual Returns')\n",
    "    plt.plot(predictions['mean_prediction'], label='Predicted Returns')\n",
    "    plt.fill_between(range(len(predictions['lower_ci'])), \n",
    "                     predictions['lower_ci'], \n",
    "                     predictions['upper_ci'], \n",
    "                     alpha=0.2)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
