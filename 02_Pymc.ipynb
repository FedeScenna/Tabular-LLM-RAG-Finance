{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "conn = sqlite3.connect(\"data/database.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM price_data\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>garman_klass_vol</th>\n",
       "      <th>rsi</th>\n",
       "      <th>bb_low</th>\n",
       "      <th>...</th>\n",
       "      <th>return_2d</th>\n",
       "      <th>return_3d</th>\n",
       "      <th>return_6d</th>\n",
       "      <th>return_9d</th>\n",
       "      <th>return_12d</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-27 00:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>39.250000</td>\n",
       "      <td>38.580002</td>\n",
       "      <td>38.700001</td>\n",
       "      <td>1703500.0</td>\n",
       "      <td>-0.002277</td>\n",
       "      <td>42.551154</td>\n",
       "      <td>3.572676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000773</td>\n",
       "      <td>-0.007624</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>-0.002268</td>\n",
       "      <td>-0.004470</td>\n",
       "      <td>-0.013229</td>\n",
       "      <td>-0.040100</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.050537</td>\n",
       "      <td>-0.007434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-27 00:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>27.285000</td>\n",
       "      <td>28.120001</td>\n",
       "      <td>27.257500</td>\n",
       "      <td>28.105000</td>\n",
       "      <td>382274800.0</td>\n",
       "      <td>-0.007667</td>\n",
       "      <td>45.914745</td>\n",
       "      <td>3.195314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017141</td>\n",
       "      <td>-0.009763</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>-0.001093</td>\n",
       "      <td>-0.002072</td>\n",
       "      <td>0.073535</td>\n",
       "      <td>-0.020393</td>\n",
       "      <td>-0.015092</td>\n",
       "      <td>0.155138</td>\n",
       "      <td>0.208851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-27 00:00:00</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>63.099998</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>62.200001</td>\n",
       "      <td>62.330002</td>\n",
       "      <td>6532300.0</td>\n",
       "      <td>-0.059758</td>\n",
       "      <td>41.454726</td>\n",
       "      <td>3.738412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>-0.003754</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>-0.005141</td>\n",
       "      <td>0.072632</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>-0.073537</td>\n",
       "      <td>0.175087</td>\n",
       "      <td>-0.034093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-27 00:00:00</td>\n",
       "      <td>ABT</td>\n",
       "      <td>43.680000</td>\n",
       "      <td>44.020000</td>\n",
       "      <td>43.430000</td>\n",
       "      <td>43.880001</td>\n",
       "      <td>4847400.0</td>\n",
       "      <td>-0.013836</td>\n",
       "      <td>39.157346</td>\n",
       "      <td>3.615259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002054</td>\n",
       "      <td>-0.006106</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>-0.002338</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>-0.030629</td>\n",
       "      <td>0.048403</td>\n",
       "      <td>0.014877</td>\n",
       "      <td>0.151120</td>\n",
       "      <td>-0.068622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-27 00:00:00</td>\n",
       "      <td>ACGL</td>\n",
       "      <td>19.953333</td>\n",
       "      <td>20.160000</td>\n",
       "      <td>19.683332</td>\n",
       "      <td>19.760000</td>\n",
       "      <td>1379700.0</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>58.501939</td>\n",
       "      <td>2.967072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>-0.064490</td>\n",
       "      <td>-0.056542</td>\n",
       "      <td>0.171240</td>\n",
       "      <td>-0.082922</td>\n",
       "      <td>-0.165375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date ticker      close       high        low       open  \\\n",
       "0  2015-01-27 00:00:00      A  38.750000  39.250000  38.580002  38.700001   \n",
       "1  2015-01-27 00:00:00   AAPL  27.285000  28.120001  27.257500  28.105000   \n",
       "2  2015-01-27 00:00:00   ABBV  63.099998  63.500000  62.200001  62.330002   \n",
       "3  2015-01-27 00:00:00    ABT  43.680000  44.020000  43.430000  43.880001   \n",
       "4  2015-01-27 00:00:00   ACGL  19.953333  20.160000  19.683332  19.760000   \n",
       "\n",
       "        volume  garman_klass_vol        rsi    bb_low  ...  return_2d  \\\n",
       "0    1703500.0         -0.002277  42.551154  3.572676  ...  -0.000773   \n",
       "1  382274800.0         -0.007667  45.914745  3.195314  ...  -0.017141   \n",
       "2    6532300.0         -0.059758  41.454726  3.738412  ...   0.005352   \n",
       "3    4847400.0         -0.013836  39.157346  3.615259  ...  -0.002054   \n",
       "4    1379700.0         -0.000351  58.501939  2.967072  ...   0.003780   \n",
       "\n",
       "   return_3d  return_6d  return_9d  return_12d    Mkt-RF       SMB       HML  \\\n",
       "0  -0.007624   0.002167  -0.002268   -0.004470 -0.013229 -0.040100  0.049200   \n",
       "1  -0.009763   0.004893  -0.001093   -0.002072  0.073535 -0.020393 -0.015092   \n",
       "2   0.000635  -0.003754  -0.000509   -0.005141  0.072632  0.045400 -0.073537   \n",
       "3  -0.006106  -0.003058  -0.002338   -0.003285 -0.030629  0.048403  0.014877   \n",
       "4   0.001060   0.001709   0.001308    0.000321 -0.064490 -0.056542  0.171240   \n",
       "\n",
       "        RMW       CMA  \n",
       "0  0.050537 -0.007434  \n",
       "1  0.155138  0.208851  \n",
       "2  0.175087 -0.034093  \n",
       "3  0.151120 -0.068622  \n",
       "4 -0.082922 -0.165375  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [mu_alpha, sigma_alpha, mu_betas, sigma_betas, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1500' class='' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1500/1500 02:07&lt;00:00 Sampling chain 0, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1500' class='' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1500/1500 03:11&lt;00:00 Sampling chain 1, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 500 tune and 1_000 draw iterations (1_000 + 2_000 draws total) took 319 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (24877,4) and (4,1000,2) not aligned: 4 (dim 1) != 1000 (dim 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 177\u001b[0m\n\u001b[0;32m    174\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 177\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 159\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    156\u001b[0m trace \u001b[38;5;241m=\u001b[39m model_runner\u001b[38;5;241m.\u001b[39mrun_inference(bayesian_model)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m    162\u001b[0m performance \u001b[38;5;241m=\u001b[39m model_runner\u001b[38;5;241m.\u001b[39mevaluate_predictions(predictions)\n",
      "Cell \u001b[1;32mIn[6], line 120\u001b[0m, in \u001b[0;36mFinancialBayesianModel.predict\u001b[1;34m(self, trace)\u001b[0m\n\u001b[0;32m    117\u001b[0m sigma \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mposterior[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Predict on test data\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m y_pred_samples \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_betas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_returns\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test,\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m: y_pred_samples\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower_ci\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mpercentile(y_pred_samples, \u001b[38;5;241m2.5\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper_ci\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mpercentile(y_pred_samples, \u001b[38;5;241m97.5\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    127\u001b[0m }\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (24877,4) and (4,1000,2) not aligned: 4 (dim 1) != 1000 (dim 1)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class FinancialBayesianModel:\n",
    "    def __init__(self, data, max_tickers=10):\n",
    "        \"\"\"\n",
    "        Initialize the Bayesian financial model with ticker limit\n",
    "        \n",
    "        Parameters:\n",
    "        data (pd.DataFrame): Financial time series data\n",
    "        max_tickers (int): Maximum number of unique tickers to process\n",
    "        \"\"\"\n",
    "        # Limit the number of unique tickers\n",
    "        unique_tickers = data['ticker'].unique()\n",
    "        if len(unique_tickers) > max_tickers:\n",
    "            selected_tickers = np.random.choice(unique_tickers, max_tickers, replace=False)\n",
    "            self.original_data = data[data['ticker'].isin(selected_tickers)].copy()\n",
    "        else:\n",
    "            self.original_data = data.copy()\n",
    "        \n",
    "        self.data = None\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def preprocess_data(self, \n",
    "                         features=['close', 'volume', 'rsi', 'sharpe_ratio'],\n",
    "                         target='return_2d', \n",
    "                         test_size=0.2):\n",
    "        \"\"\"\n",
    "        Preprocess data with memory-efficient approach\n",
    "        \"\"\"\n",
    "        # Sort and prepare data\n",
    "        df = self.original_data.sort_values(['date', 'ticker'])\n",
    "        \n",
    "        # Select and prepare columns\n",
    "        cols_to_use = features + [target, 'ticker']\n",
    "        df_subset = df[cols_to_use].dropna()\n",
    "        \n",
    "        # Use categorical encoding for tickers\n",
    "        df_subset['ticker_code'] = pd.Categorical(df_subset['ticker']).codes\n",
    "        \n",
    "        # Prepare features and target\n",
    "        X = df_subset[features].values\n",
    "        y = df_subset[target].values\n",
    "        tickers = df_subset['ticker_code'].values\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Split data with stratification\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test, \\\n",
    "        self.tickers_train, self.tickers_test = \\\n",
    "            train_test_split(X_scaled, y, tickers, \n",
    "                             test_size=test_size, \n",
    "                             stratify=tickers, \n",
    "                             random_state=42)\n",
    "        \n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.unique_tickers = np.unique(tickers)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_hierarchical_model(self):\n",
    "        \"\"\"\n",
    "        Simplified hierarchical model to avoid recursion\n",
    "        \"\"\"\n",
    "        with pm.Model() as model:\n",
    "            # Global parameters with less complexity\n",
    "            mu_alpha = pm.Normal('mu_alpha', mu=0, sigma=1)\n",
    "            sigma_alpha = pm.HalfNormal('sigma_alpha', sigma=0.5)\n",
    "            \n",
    "            # Global coefficients\n",
    "            mu_betas = pm.Normal('mu_betas', mu=0, sigma=0.5, \n",
    "                                 shape=self.X_train.shape[1])\n",
    "            sigma_betas = pm.HalfNormal('sigma_betas', sigma=0.5, \n",
    "                                        shape=self.X_train.shape[1])\n",
    "            \n",
    "            # Model variance\n",
    "            sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "            \n",
    "            # Linear model with vectorized computation\n",
    "            mu = pm.math.dot(self.X_train, mu_betas)\n",
    "            \n",
    "            # Likelihood\n",
    "            likelihood = pm.Normal('returns', \n",
    "                                   mu=mu, \n",
    "                                   sigma=sigma, \n",
    "                                   observed=self.y_train)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def run_inference(self, model, draws=1000, tune=500):\n",
    "        \"\"\"\n",
    "        Run inference with reduced complexity\n",
    "        \"\"\"\n",
    "        with model:\n",
    "            # Use NUTS sampler with adjusted parameters\n",
    "            trace = pm.sample(draws=draws, \n",
    "                              tune=tune, \n",
    "                              #return_inferrable=True,\n",
    "                              cores=1,  # Avoid multiprocessing issues\n",
    "                              target_accept=0.9)\n",
    "        \n",
    "        return trace\n",
    "    \n",
    "    def predict(self, trace):\n",
    "        \"\"\"\n",
    "        Make predictions with simplified approach\n",
    "        \"\"\"\n",
    "        # Extract posterior samples\n",
    "        mu_betas = trace.posterior['mu_betas']\n",
    "        sigma = trace.posterior['sigma']\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred_samples = np.dot(self.X_test, mu_betas.T)\n",
    "        \n",
    "        return {\n",
    "            'true_returns': self.y_test,\n",
    "            'mean_prediction': y_pred_samples.mean(axis=0),\n",
    "            'lower_ci': np.percentile(y_pred_samples, 2.5, axis=0),\n",
    "            'upper_ci': np.percentile(y_pred_samples, 97.5, axis=0)\n",
    "        }\n",
    "    \n",
    "    def evaluate_predictions(self, predictions):\n",
    "        \"\"\"\n",
    "        Evaluate model predictions\n",
    "        \"\"\"\n",
    "        mse = np.mean((predictions['true_returns'] - predictions['mean_prediction'])**2)\n",
    "        mae = np.mean(np.abs(predictions['true_returns'] - predictions['mean_prediction']))\n",
    "        \n",
    "        return {\n",
    "            'MSE': mse,\n",
    "            'MAE': mae,\n",
    "            'Coverage': np.mean((predictions['true_returns'] >= predictions['lower_ci']) & \n",
    "                                (predictions['true_returns'] <= predictions['upper_ci']))\n",
    "        }\n",
    "\n",
    "def main():\n",
    "   \n",
    "    # Initialize model with ticker limit\n",
    "    model_runner = FinancialBayesianModel(df, max_tickers=50)\n",
    "    \n",
    "    # Preprocess data\n",
    "    model_runner.preprocess_data(\n",
    "        features=['close', 'volume', 'rsi', 'sharpe_ratio'],\n",
    "        target='return_2d'\n",
    "    )\n",
    "    \n",
    "    # Create and run model\n",
    "    bayesian_model = model_runner.create_hierarchical_model()\n",
    "    trace = model_runner.run_inference(bayesian_model)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model_runner.predict(trace)\n",
    "    \n",
    "    # Evaluate\n",
    "    performance = model_runner.evaluate_predictions(predictions)\n",
    "    print(\"Performance Metrics:\", performance)\n",
    "    \n",
    "    # Optional visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(predictions['true_returns'], label='Actual Returns')\n",
    "    plt.plot(predictions['mean_prediction'], label='Predicted Returns')\n",
    "    plt.fill_between(range(len(predictions['lower_ci'])), \n",
    "                     predictions['lower_ci'], \n",
    "                     predictions['upper_ci'], \n",
    "                     alpha=0.2)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
